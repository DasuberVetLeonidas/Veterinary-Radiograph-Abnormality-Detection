{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.4.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import random_split\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import wandb\n",
    "import numbers\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model_name = \"Efficientnetb5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 16789<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201024_154412-ar0ka2t1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201024_154412-ar0ka2t1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">likely-snowflake-1</strong>: <a href=\"https://wandb.ai/szho6430/Direct%20Finetune%20with%20Dataset%20Ver.2/runs/ar0ka2t1\" target=\"_blank\">https://wandb.ai/szho6430/Direct%20Finetune%20with%20Dataset%20Ver.2/runs/ar0ka2t1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.8<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">tough-frost-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/szho6430/Direct%20Finetune%20with%20Dataset%20Ver.2\" target=\"_blank\">https://wandb.ai/szho6430/Direct%20Finetune%20with%20Dataset%20Ver.2</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/szho6430/Direct%20Finetune%20with%20Dataset%20Ver.2/runs/unjc1elx\" target=\"_blank\">https://wandb.ai/szho6430/Direct%20Finetune%20with%20Dataset%20Ver.2/runs/unjc1elx</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201024_154452-unjc1elx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_dir = \"/media/dasleo/LEOHDD/data/AnimalDatasetV2CVs/\"\n",
    "\n",
    "hyperparameter_defaults = dict(\n",
    "    input_size = 1024,\n",
    "    batch_size = 5,\n",
    "    training_depth = 19,\n",
    "    num_epochs = 100,\n",
    "    learning_rate = 1e-5,\n",
    "    betas = (0.9,0.999),\n",
    "    eps = 1e-8,\n",
    "    amsgrad = True,\n",
    ")\n",
    "\n",
    "wandb.init(project=\"Direct Finetune with Dataset Ver.2\",config=hyperparameter_defaults)\n",
    "wbconfig = wandb.config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "'''Compute balanced classweight using scikit-learn'''\n",
    "from sklearn.utils import class_weight\n",
    "meta = pd.read_csv('./meta.csv')\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(meta['Normal_Abnormal']),\n",
    "                                                 meta['Normal_Abnormal'])\n",
    "class_weights = torch.tensor([class_weights],dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(image):    \n",
    "    w, h = image.size\n",
    "    max_wh = np.max([w, h])\n",
    "    h_padding = (max_wh - w) / 2\n",
    "    v_padding = (max_wh - h) / 2\n",
    "    l_pad = h_padding if h_padding % 1 == 0 else h_padding+0.5\n",
    "    t_pad = v_padding if v_padding % 1 == 0 else v_padding+0.5\n",
    "    r_pad = h_padding if h_padding % 1 == 0 else h_padding-0.5\n",
    "    b_pad = v_padding if v_padding % 1 == 0 else v_padding-0.5\n",
    "    padding = (int(l_pad), int(t_pad), int(r_pad), int(b_pad))\n",
    "    return padding\n",
    "\n",
    "class NewPad(object):\n",
    "    def __init__(self, fill=0, padding_mode='constant'):\n",
    "        assert isinstance(fill, (numbers.Number, str, tuple))\n",
    "        assert padding_mode in ['constant', 'edge', 'reflect', 'symmetric']\n",
    "\n",
    "        self.fill = fill\n",
    "        self.padding_mode = padding_mode\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be padded.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Padded image.\n",
    "        \"\"\"\n",
    "        return F.pad(img, get_padding(img), self.fill, self.padding_mode)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(padding={0}, fill={1}, padding_mode={2})'.\\\n",
    "            format(self.fill, self.padding_mode)\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer,\n",
    "                num_epochs, log_path, model_save_path):\n",
    "    print(f'Training log is saved to {log_path}')\n",
    "    with open(log_path,\"w\") as file:\n",
    "        file.write(\"\\n\")\n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        out_text = \"\"\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        out_text = '\\n' +'Epoch {}/{}'.format(epoch, num_epochs - 1) + '\\n' + '-' * 10 +'\\n'\n",
    "        with open(log_path,\"a\") as file:\n",
    "            file.write(out_text)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    wandb.log({\"Training Loss\":loss})\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            if phase == 'train':\n",
    "                wandb.log({\"Epoch Training Accuracy\":epoch_acc*100})\n",
    "            if phase == 'val':\n",
    "                wandb.log({\"Epoch Validation Accuracy\":epoch_acc*100})\n",
    "            out_text ='{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc)+\"\\n\"\n",
    "            with open(log_path,\"a\") as file:\n",
    "                file.write(out_text)\n",
    "            save_path = model_save_path + '/' + str(epoch) + '.h5'\n",
    "            torch.save(model.state_dict(),save_path)\n",
    "            if phase == \"val\":\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    out_text = \"\\n\"+'Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60) + '\\n' + 'Best val Acc: {:4f}'.format(best_acc) +'\\n'\n",
    "    with open(log_path,\"a\") as file:\n",
    "        file.write(out_text)\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    save_path = model_save_path + '/' + 'best.h5'\n",
    "    return model, val_acc_history,train_acc_history\n",
    "\n",
    "\n",
    "def test(model, dataloaders, device):\n",
    "    labels = []\n",
    "    preds = []\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    for inputs,label in dataloaders['test']:\n",
    "        inputs.to(device)\n",
    "        total += 1\n",
    "        outputs = model(inputs)\n",
    "        _,pred = torch.max(outputs,1).to('cpu').detach()  \n",
    "    labels.append(int(label.detach()))\n",
    "    preds.append(int(pred))\n",
    "    return labels,preds\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        NewPad(),\n",
    "        transforms.Resize(wbconfig.input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.1523, 0.1523, 0.1523], [0.1402, 0.1402, 0.1402])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        NewPad(),\n",
    "        transforms.Resize(wbconfig.input_size),\n",
    "        transforms.CenterCrop(wbconfig.input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.1523, 0.1523, 0.1523], [0.1402, 0.1402, 0.1402])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        NewPad(),\n",
    "        transforms.Resize(wbconfig.input_size),\n",
    "        transforms.CenterCrop(wbconfig.input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.1523, 0.1523, 0.1523], [0.1402, 0.1402, 0.1402])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different CV Numbers\n",
    "models = {}\n",
    "\n",
    "for cv in np.arange(1,5+1):\n",
    "    \n",
    "    '''Step 1: Build up dataset and dataloader'''\n",
    "    data_dir = cv_dir+'CV'+str(cv)\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), \n",
    "                                              data_transforms[x]) for x in ['train', 'test']}\n",
    "    [train_set,val_set] = random_split(image_datasets['train'],\n",
    "                                       [int(len(image_datasets['train'])*0.9),\n",
    "                                        int(len(image_datasets['train'])*0.1)])\n",
    "    #print(\"The class labels and indexes are\",'\\t',image_datasets['train'].class_to_idx)\n",
    "    dataloaders_dict = {}\n",
    "    dataloaders_dict['train'] = torch.utils.data.DataLoader(train_set,\n",
    "                                                   batch_size=wbconfig.batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=4)\n",
    "    dataloaders_dict['val'] = torch.utils.data.DataLoader(val_set,\n",
    "                                                       batch_size=1,\n",
    "                                                       shuffle=False,\n",
    "                                                       num_workers=2)\n",
    "    dataloaders_dict['test'] = torch.utils.data.DataLoader(image_datasets['test'],\n",
    "                                                       batch_size=1,\n",
    "                                                       shuffle=False,\n",
    "                                                       num_workers=2)\n",
    "    \n",
    "    '''Step 2: Set up model'''\n",
    "    models[cv] = EfficientNet.from_pretrained('efficientnet-b5',num_classes=2)\n",
    "    for _,param in models[cv].named_parameters():\n",
    "        param.requires_grad = False\n",
    "    for name,param in models[cv].named_parameters():\n",
    "        if name.split('.')[1].isdigit():\n",
    "            if int(name.split('.')[1]) > wbconfig.training_depth:\n",
    "                param.requires_grad = True\n",
    "    models[cv]._conv_head.weight.requires_grad = True\n",
    "    models[cv]._bn1.weight.requires_grad = True\n",
    "    models[cv]._bn1.bias.requires_grad = True\n",
    "    models[cv]._fc.weight.requires_grad = True\n",
    "    models[cv]._fc.bias.requires_grad = True\n",
    "    # collect parameters to be trained\n",
    "    params_to_update = []\n",
    "    for name,param in models[cv].named_parameters():\n",
    "        if param.requires_grad:\n",
    "            params_to_update.append(param)\n",
    "    \n",
    "    '''Step 3: Build required stuff for training helper function'''\n",
    "    wandb.watch(models[cv],log='all')\n",
    "    models[cv].to(device)\n",
    "    dataloaders = dataloaders_dict\n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights).to(device)\n",
    "    optimizer = optim.Adam(params_to_update,\n",
    "                          lr = wbconfig.learning_rate,\n",
    "                          betas=wbconfig.betas,\n",
    "                          eps=wbconfig.eps,\n",
    "                          amsgrad=wbconfig.amsgrad)\n",
    "    num_epochs = wbconfig.num_epochs\n",
    "    log_path = './Direct_Finetune/log/CV'+str(cv)+'_log.txt'\n",
    "    model_save_path = './Direct_Finetune/CV'+str(cv)\n",
    "    \n",
    "    '''Step 4: Train model'''\n",
    "    trained_model,val_acc_history,train_acc_history  = train_model(models[cv],\n",
    "                                                                   dataloaders_dict, \n",
    "                                                                   criterion,\n",
    "                                                                   optimizer,\n",
    "                                                                   num_epochs,\n",
    "                                                                   log_path,\n",
    "                                                                   model_save_path=model_save_path)\n",
    "    \n",
    "    '''Step 5: Draw Training History Figures'''\n",
    "    fig = plt.title(\"Validation and Training Accuracy\")\n",
    "    fig = plt.xlabel(\"Epochs\")\n",
    "    fig = plt.ylabel(\"Accuracy\")\n",
    "    fig = plt.plot(range(1,num_epochs+1),val_acc_history,label=\"Validation\")\n",
    "    fig = plt.plot(range(1,num_epochs+1),train_acc_history,label=\"Training\")\n",
    "    fig = plt.ylim((0,1.))\n",
    "    fig = plt.xticks(np.arange(1, num_epochs+1, 1))\n",
    "    fig = plt.legend()\n",
    "    fig_save_path = './Direct_Finetune/log/CV'+str(cv)+'_Train_Val_Log.png'\n",
    "    fig.figure.savefig(fig_save_path)\n",
    "    \n",
    "    '''Step 6: Obtain Preliminary Classification Report'''\n",
    "    y_true,y_pred = test(model = trained_model,dataloaders = dataloaders_dict, device = device)\n",
    "    report = classification_report(y_true=y_true,y_pred=y_pred)\n",
    "    report_save_path = './Direct_Finetune/log/CV'+str(cv)+'_Report.txt'\n",
    "    with open(report_save_path,\"w\") as file:\n",
    "        file.write(report)\n",
    "    \n",
    "    '''Final Step: purging before next CV'''\n",
    "    del trained_model, image_datasets, dataloaders_dict, dataloaders, val_acc_history, train_acc_history, fig, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
